{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (22.10.0)\n",
      "Requirement already satisfied: cryptography>=3.4.6 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (41.0.3)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (1.0.4)\n",
      "Requirement already satisfied: parsel>=1.5.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (1.6.0)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (23.2.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (1.5.0)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (18.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (1.21.0)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (5.4.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (0.1.16)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (0.3.0)\n",
      "Requirement already satisfied: setuptools in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (68.0.0)\n",
      "Requirement already satisfied: packaging in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (23.1)\n",
      "Requirement already satisfied: tldextract in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (3.2.0)\n",
      "Requirement already satisfied: lxml>=4.3.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (4.9.3)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from cryptography>=3.4.6->scrapy) (1.15.1)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from itemloaders>=1.0.1->scrapy) (0.10.0)\n",
      "Requirement already satisfied: six>=1.6.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from parsel>=1.5.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: attrs>=16.0.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from service-identity>=18.1.0->scrapy) (22.1.0)\n",
      "Requirement already satisfied: pyasn1-modules in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: pyasn1 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: constantly>=15.1 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from Twisted>=18.9.0->scrapy) (15.1.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from Twisted>=18.9.0->scrapy) (21.3.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from Twisted>=18.9.0->scrapy) (20.2.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from Twisted>=18.9.0->scrapy) (4.7.1)\n",
      "Requirement already satisfied: idna in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from tldextract->scrapy) (3.4)\n",
      "Requirement already satisfied: requests>=2.1.0 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from tldextract->scrapy) (2.31.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from tldextract->scrapy) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from tldextract->scrapy) (3.9.0)\n",
      "Requirement already satisfied: pycparser in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.4.6->scrapy) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/geraldine.mitaine/anaconda3/lib/python3.11/site-packages (from requests>=2.1.0->tldextract->scrapy) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Downloading Scrapy-2.11.1-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting Twisted>=18.9.0 (from scrapy)\n",
      "  Downloading twisted-23.10.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting cryptography>=36.0.0 (from scrapy)\n",
      "  Downloading cryptography-42.0.4-cp39-abi3-macosx_10_12_universal2.whl.metadata (5.3 kB)\n",
      "Collecting cssselect>=0.9.1 (from scrapy)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting itemloaders>=1.0.1 (from scrapy)\n",
      "  Downloading itemloaders-1.1.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting parsel>=1.5.0 (from scrapy)\n",
      "  Downloading parsel-1.8.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pyOpenSSL>=21.0.0 (from scrapy)\n",
      "  Downloading pyOpenSSL-24.0.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting queuelib>=1.4.2 (from scrapy)\n",
      "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting service-identity>=18.1.0 (from scrapy)\n",
      "  Downloading service_identity-24.1.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting w3lib>=1.17.0 (from scrapy)\n",
      "  Downloading w3lib-2.1.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting zope.interface>=5.1.0 (from scrapy)\n",
      "  Downloading zope.interface-6.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protego>=0.1.15 (from scrapy)\n",
      "  Downloading Protego-0.3.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting itemadapter>=0.1.0 (from scrapy)\n",
      "  Downloading itemadapter-0.8.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting setuptools (from scrapy)\n",
      "  Downloading setuptools-69.1.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: packaging in /Users/geraldine.mitaine/Library/Python/3.12/lib/python/site-packages (from scrapy) (23.2)\n",
      "Collecting tldextract (from scrapy)\n",
      "  Downloading tldextract-5.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting lxml>=4.4.1 (from scrapy)\n",
      "  Downloading lxml-5.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
      "  Downloading PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=36.0.0->scrapy)\n",
      "  Downloading cffi-1.16.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting jmespath>=0.9.5 (from itemloaders>=1.0.1->scrapy)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from service-identity>=18.1.0->scrapy) (23.2.0)\n",
      "Collecting pyasn1 (from service-identity>=18.1.0->scrapy)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyasn1-modules (from service-identity>=18.1.0->scrapy)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting automat>=0.8.0 (from Twisted>=18.9.0->scrapy)\n",
      "  Downloading Automat-22.10.0-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting constantly>=15.1 (from Twisted>=18.9.0->scrapy)\n",
      "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting hyperlink>=17.1.1 (from Twisted>=18.9.0->scrapy)\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting incremental>=22.10.0 (from Twisted>=18.9.0->scrapy)\n",
      "  Downloading incremental-22.10.0-py2.py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting typing-extensions>=4.2.0 (from Twisted>=18.9.0->scrapy)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tldextract->scrapy) (3.6)\n",
      "Requirement already satisfied: requests>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tldextract->scrapy) (2.31.0)\n",
      "Collecting requests-file>=1.4 (from tldextract->scrapy)\n",
      "  Downloading requests_file-2.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting filelock>=3.0.8 (from tldextract->scrapy)\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: six in /Users/geraldine.mitaine/Library/Python/3.12/lib/python/site-packages (from automat>=0.8.0->Twisted>=18.9.0->scrapy) (1.16.0)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->scrapy)\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.1.0->tldextract->scrapy) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.1.0->tldextract->scrapy) (2024.2.2)\n",
      "Downloading Scrapy-2.11.1-py2.py3-none-any.whl (287 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.8/287.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-42.0.4-cp39-abi3-macosx_10_12_universal2.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading itemadapter-0.8.0-py3-none-any.whl (11 kB)\n",
      "Downloading itemloaders-1.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading lxml-5.1.0-cp312-cp312-macosx_11_0_arm64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading parsel-1.8.1-py2.py3-none-any.whl (17 kB)\n",
      "Downloading Protego-0.3.0-py2.py3-none-any.whl (8.5 kB)\n",
      "Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
      "Downloading pyOpenSSL-24.0.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading service_identity-24.1.0-py3-none-any.whl (12 kB)\n",
      "Downloading twisted-23.10.0-py3-none-any.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n",
      "Downloading zope.interface-6.2-cp312-cp312-macosx_11_0_arm64.whl (202 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.8/202.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-69.1.0-py3-none-any.whl (819 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tldextract-5.1.1-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
      "Downloading cffi-1.16.0-cp312-cp312-macosx_11_0_arm64.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
      "Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading requests_file-2.0.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyDispatcher, incremental, w3lib, typing-extensions, setuptools, queuelib, pycparser, pyasn1, protego, lxml, jmespath, itemadapter, hyperlink, filelock, cssselect, constantly, automat, zope.interface, requests-file, pyasn1-modules, parsel, cffi, Twisted, tldextract, itemloaders, cryptography, service-identity, pyOpenSSL, scrapy\n",
      "Successfully installed PyDispatcher-2.0.7 Twisted-23.10.0 automat-22.10.0 cffi-1.16.0 constantly-23.10.4 cryptography-42.0.4 cssselect-1.2.0 filelock-3.13.1 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.8.0 itemloaders-1.1.0 jmespath-1.0.1 lxml-5.1.0 parsel-1.8.1 protego-0.3.0 pyOpenSSL-24.0.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 pycparser-2.21 queuelib-1.6.2 requests-file-2.0.0 scrapy-2.11.1 service-identity-24.1.0 setuptools-69.1.0 tldextract-5.1.1 typing-extensions-4.9.0 w3lib-2.1.2 zope.interface-6.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scrapy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'src/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1_randomquote.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# If file already exists, delete it before crawling (because Scrapy will \u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# concatenate the last and new results otherwise)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msrc/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     37\u001b[0m         os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filename)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Declare a new CrawlerProcess with some settings\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m## USER_AGENT => Simulates a browser on an OS\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m## LOG_LEVEL => Minimal Level of Log \u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m## FEEDS => Where the file will be stored \u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m## More info on built-in settings => https://docs.scrapy.org/en/latest/topics/settings.html?highlight=settings#settings\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'src/'"
     ]
    }
   ],
   "source": [
    "#Import os => Library used to easily manipulate operating systems\n",
    "## More info => https://docs.python.org/3/library/os.html\n",
    "import os \n",
    "\n",
    "# Import logging => Library used for logs manipulation \n",
    "## More info => https://docs.python.org/3/library/logging.html\n",
    "import logging\n",
    "\n",
    "# Import scrapy and scrapy.crawler \n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class RandomQuoteSpider(scrapy.Spider):\n",
    "    # Name of your spider\n",
    "    name = \"randomquote\"\n",
    "\n",
    "    # Url to start your spider from \n",
    "    start_urls = [\n",
    "        'http://quotes.toscrape.com/random',\n",
    "    ]\n",
    "\n",
    "    # Callback function that will be called when starting your spider\n",
    "    # It will get text, author and tags of the first <div> with class=\"quote\"\n",
    "    def parse(self, response):\n",
    "        return {\n",
    "            'text': response.xpath(\"/html/body/div/div[2]/div[1]/div/span[1]/text()\").get(),\n",
    "            'author': response.xpath('/html/body/div/div[2]/div[1]/div/span[2]/small/text()').get(),\n",
    "            'tags': response.xpath('/html/body/div/div[2]/div[1]/div/div/a/text()').getall(),\n",
    "        }\n",
    "\n",
    "# Name of the file where the results will be saved\n",
    "filename = \"1_randomquote.json\"\n",
    "\n",
    "# If file already exists, delete it before crawling (because Scrapy will \n",
    "# concatenate the last and new results otherwise)\n",
    "if filename in os.listdir('src/'):\n",
    "        os.remove('src/' + filename)\n",
    "\n",
    "# Declare a new CrawlerProcess with some settings\n",
    "## USER_AGENT => Simulates a browser on an OS\n",
    "## LOG_LEVEL => Minimal Level of Log \n",
    "## FEEDS => Where the file will be stored \n",
    "## More info on built-in settings => https://docs.scrapy.org/en/latest/topics/settings.html?highlight=settings#settings\n",
    "process = CrawlerProcess(settings = {\n",
    "    'USER_AGENT': 'Chrome/97.0',\n",
    "    'LOG_LEVEL': logging.INFO,\n",
    "    \"FEEDS\": {\n",
    "        'src/' + filename : {\"format\": \"json\"},\n",
    "    }\n",
    "})\n",
    "\n",
    "# Start the crawling using the spider you defined above\n",
    "process.crawl(RandomQuoteSpider)\n",
    "process.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
